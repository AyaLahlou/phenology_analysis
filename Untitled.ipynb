{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258ac00-84ea-4303-934b-94e7cf68e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d6b6a-efbf-435f-8ba7-f20b1101f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from itertools import product\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def predictions_to_map(data_path, pred_path, coord_path):\n",
    "    \"\"\" Match original data to predictions and corresponding coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : str\n",
    "        path to original processed data dictionnary \n",
    "    pred_path : str\n",
    "        path to predictions dictionnary\n",
    "    coord_path : str\n",
    "        path to dataframe matching location index to coordinates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Dataframe\n",
    "        dataframe with groundtruth values, predictions and corresponding time and coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(data_path,'rb') as fp:\n",
    "        data = pickle.load(fp)\n",
    "    with open(pred_path,'rb') as fp:\n",
    "        preds = pickle.load(fp)\n",
    "\n",
    "    coords=pd.read_parquet(coord_path)\n",
    "    coords= coords.drop_duplicates()\n",
    "\n",
    "    # get location ID and grountruth CSIF from original data\n",
    "    df = pd.DataFrame({\n",
    "        'Index': data['data_sets']['test']['id'].flatten(),\n",
    "        'Flattened_Values': data['data_sets']['test']['target'].flatten(),})\n",
    "    #retrive future drivers map from predictions\n",
    "    df['pred_05'] = preds['predicted_quantiles'][:, :, 1].flatten()\n",
    "    df['fut_tmin'] = preds['future_selection_weights'][:, :, 0].flatten()\n",
    "    df['fut_tmax'] = preds['future_selection_weights'][:, :, 1].flatten()\n",
    "    df['fut_rad'] = preds['future_selection_weights'][:, :, 2].flatten()\n",
    "    df['fut_precip'] = preds['future_selection_weights'][:, :, 3].flatten()\n",
    "    df['fut_photo'] = preds['future_selection_weights'][:, :, 4].flatten()\n",
    "    df['fut_sm'] = preds['future_selection_weights'][:, :, 5].flatten()\n",
    "\n",
    "    df[['location_id', 'time_id']] = df['Index'].str.split('_', n=1, expand=True)\n",
    "    df['location_id'] = df['location_id'].astype(int)\n",
    "    df['time_id'] = pd.to_datetime(df['time_id'])\n",
    "    df = df.sort_values(by=['location_id','time_id'])\n",
    "    df['doy']=df['time_id'].dt.dayofyear\n",
    "    df['year']= df['time_id'].dt.year\n",
    "    df['month']= df['time_id'].dt.month\n",
    "    df['day']= df['time_id'].dt.day\n",
    "    df= df.rename(columns={'Flattened_Values': 'CSIF', 'location_id': 'location', 'time_id': 'time'})\n",
    "    df = df.drop(columns=['Index'])\n",
    "    df_coord = pd.merge(coords, df, on='location', how='left')\n",
    "    \n",
    "    return df_coord\n",
    "\n",
    "def merge_clusters_df(df_list, START_DOY, END_DOY):\n",
    "    \"\"\" This function \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
